{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from  sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>log_price</th>\n",
       "      <th>name_processed</th>\n",
       "      <th>brand_name_processed</th>\n",
       "      <th>category_name_preprocessed</th>\n",
       "      <th>Tier_2</th>\n",
       "      <th>Tier_3</th>\n",
       "      <th>item_description_processed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Hold Alyssa Frye Harness boots 12R, Sz 7</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Shoes/Boots</td>\n",
       "      <td>Frye</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>Good used condition Women's Fyre harness boots...</td>\n",
       "      <td>4.382027</td>\n",
       "      <td>hold alyssa frye harness boots 12r sz 7</td>\n",
       "      <td>frye</td>\n",
       "      <td>women/shoe/boots</td>\n",
       "      <td>shoe</td>\n",
       "      <td>boots</td>\n",
       "      <td>good used condition women fyre harness boots l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Steve Madden booties</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Shoes/Boots</td>\n",
       "      <td>Steve Madden</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>The brand is actually \"Steven\" by Steve Madden...</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>steve madden booties</td>\n",
       "      <td>steve madden</td>\n",
       "      <td>women/shoe/boots</td>\n",
       "      <td>shoe</td>\n",
       "      <td>boots</td>\n",
       "      <td>brand actually steven steve madden steve madde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BCBG Tan Booties</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Shoes/Boots</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>Brand new! Does not include the box.</td>\n",
       "      <td>3.891820</td>\n",
       "      <td>bcbg tan booties</td>\n",
       "      <td>bcbg</td>\n",
       "      <td>women/shoe/boots</td>\n",
       "      <td>shoe</td>\n",
       "      <td>boots</td>\n",
       "      <td>brand new include box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NWT Sorel Caribou boots size 8.5</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Shoes/Boots</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>New in box. Size 8.5</td>\n",
       "      <td>4.454347</td>\n",
       "      <td>nwt sorel caribou boots size 85</td>\n",
       "      <td>sorel</td>\n",
       "      <td>women/shoe/boots</td>\n",
       "      <td>shoe</td>\n",
       "      <td>boots</td>\n",
       "      <td>new box size 85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>NIB Hunter Tiffany Mint Boots Size 5</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Shoes/Boots</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>Brand new never worn only flaw is as you can s...</td>\n",
       "      <td>5.303305</td>\n",
       "      <td>nib hunter tiffany mint boots size 5</td>\n",
       "      <td>hunter</td>\n",
       "      <td>women/shoe/boots</td>\n",
       "      <td>shoe</td>\n",
       "      <td>boots</td>\n",
       "      <td>brand new never worn flaw see picture color we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        name  item_condition_id  \\\n",
       "id                                                                \n",
       "17  Hold Alyssa Frye Harness boots 12R, Sz 7                  3   \n",
       "19                      Steve Madden booties                  3   \n",
       "42                          BCBG Tan Booties                  1   \n",
       "45          NWT Sorel Caribou boots size 8.5                  1   \n",
       "58      NIB Hunter Tiffany Mint Boots Size 5                  1   \n",
       "\n",
       "        category_name    brand_name  price  shipping  \\\n",
       "id                                                     \n",
       "17  Women/Shoes/Boots          Frye     79         1   \n",
       "19  Women/Shoes/Boots  Steve Madden     31         0   \n",
       "42  Women/Shoes/Boots           NaN     48         0   \n",
       "45  Women/Shoes/Boots           NaN     85         0   \n",
       "58  Women/Shoes/Boots        Hunter    200         0   \n",
       "\n",
       "                                     item_description  log_price  \\\n",
       "id                                                                 \n",
       "17  Good used condition Women's Fyre harness boots...   4.382027   \n",
       "19  The brand is actually \"Steven\" by Steve Madden...   3.465736   \n",
       "42               Brand new! Does not include the box.   3.891820   \n",
       "45                               New in box. Size 8.5   4.454347   \n",
       "58  Brand new never worn only flaw is as you can s...   5.303305   \n",
       "\n",
       "                             name_processed brand_name_processed  \\\n",
       "id                                                                 \n",
       "17  hold alyssa frye harness boots 12r sz 7                 frye   \n",
       "19                     steve madden booties         steve madden   \n",
       "42                         bcbg tan booties                 bcbg   \n",
       "45          nwt sorel caribou boots size 85                sorel   \n",
       "58     nib hunter tiffany mint boots size 5               hunter   \n",
       "\n",
       "   category_name_preprocessed Tier_2 Tier_3  \\\n",
       "id                                            \n",
       "17           women/shoe/boots   shoe  boots   \n",
       "19           women/shoe/boots   shoe  boots   \n",
       "42           women/shoe/boots   shoe  boots   \n",
       "45           women/shoe/boots   shoe  boots   \n",
       "58           women/shoe/boots   shoe  boots   \n",
       "\n",
       "                           item_description_processed  \n",
       "id                                                     \n",
       "17  good used condition women fyre harness boots l...  \n",
       "19  brand actually steven steve madden steve madde...  \n",
       "42                              brand new include box  \n",
       "45                                    new box size 85  \n",
       "58  brand new never worn flaw see picture color we...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the processed train dataset\n",
    "\n",
    "df =  pd.read_csv(\"train_processed.csv\",index_col=[\"id\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>name_processed</th>\n",
       "      <th>brand_name_processed</th>\n",
       "      <th>category_name_preprocessed</th>\n",
       "      <th>Tier_2</th>\n",
       "      <th>Tier_3</th>\n",
       "      <th>item_description_processed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Corral boots</td>\n",
       "      <td>2</td>\n",
       "      <td>Women/Shoes/Boots</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Corral boots in excellent condition barely used</td>\n",
       "      <td>corral boots</td>\n",
       "      <td>missing</td>\n",
       "      <td>women/shoe/boots</td>\n",
       "      <td>shoe</td>\n",
       "      <td>boots</td>\n",
       "      <td>corral boots excellent condition barely used</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Vince Camuto Riding boots size 6</td>\n",
       "      <td>2</td>\n",
       "      <td>Women/Shoes/Boots</td>\n",
       "      <td>Vince Camuto</td>\n",
       "      <td>0</td>\n",
       "      <td>super cute brown or cognac knee high riding bo...</td>\n",
       "      <td>vince camuto riding boots size 6</td>\n",
       "      <td>vince camuto</td>\n",
       "      <td>women/shoe/boots</td>\n",
       "      <td>shoe</td>\n",
       "      <td>boots</td>\n",
       "      <td>super cute brown cognac knee high riding boots...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Brand new UGG boots</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Shoes/Boots</td>\n",
       "      <td>UGG Australia</td>\n",
       "      <td>0</td>\n",
       "      <td>New in box</td>\n",
       "      <td>brand new ugg boots</td>\n",
       "      <td>ugg australia</td>\n",
       "      <td>women/shoe/boots</td>\n",
       "      <td>shoe</td>\n",
       "      <td>boots</td>\n",
       "      <td>new box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>LL Bean Boots 8\" Red sz 7M</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Shoes/Boots</td>\n",
       "      <td>L.L. Bean</td>\n",
       "      <td>0</td>\n",
       "      <td>Made to withstand winter climate.</td>\n",
       "      <td>bean boots 8 red sz 7m</td>\n",
       "      <td>ll bean</td>\n",
       "      <td>women/shoe/boots</td>\n",
       "      <td>shoe</td>\n",
       "      <td>boots</td>\n",
       "      <td>made withstand winter climate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Black UGGS cargo boot</td>\n",
       "      <td>3</td>\n",
       "      <td>Women/Shoes/Boots</td>\n",
       "      <td>UGG Australia</td>\n",
       "      <td>1</td>\n",
       "      <td>Unique, super cute and warm! EUC. Only selling...</td>\n",
       "      <td>black uggs cargo boot</td>\n",
       "      <td>ugg australia</td>\n",
       "      <td>women/shoe/boots</td>\n",
       "      <td>shoe</td>\n",
       "      <td>boots</td>\n",
       "      <td>unique super cute warm euc selling lining insi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 name  item_condition_id      category_name  \\\n",
       "id                                                                            \n",
       "46                       Corral boots                  2  Women/Shoes/Boots   \n",
       "88   Vince Camuto Riding boots size 6                  2  Women/Shoes/Boots   \n",
       "212               Brand new UGG boots                  1  Women/Shoes/Boots   \n",
       "289        LL Bean Boots 8\" Red sz 7M                  3  Women/Shoes/Boots   \n",
       "299             Black UGGS cargo boot                  3  Women/Shoes/Boots   \n",
       "\n",
       "        brand_name  shipping  \\\n",
       "id                             \n",
       "46             NaN         0   \n",
       "88    Vince Camuto         0   \n",
       "212  UGG Australia         0   \n",
       "289      L.L. Bean         0   \n",
       "299  UGG Australia         1   \n",
       "\n",
       "                                      item_description  \\\n",
       "id                                                       \n",
       "46     Corral boots in excellent condition barely used   \n",
       "88   super cute brown or cognac knee high riding bo...   \n",
       "212                                         New in box   \n",
       "289                  Made to withstand winter climate.   \n",
       "299  Unique, super cute and warm! EUC. Only selling...   \n",
       "\n",
       "                       name_processed brand_name_processed  \\\n",
       "id                                                           \n",
       "46                       corral boots              missing   \n",
       "88   vince camuto riding boots size 6         vince camuto   \n",
       "212               brand new ugg boots        ugg australia   \n",
       "289            bean boots 8 red sz 7m              ll bean   \n",
       "299             black uggs cargo boot        ugg australia   \n",
       "\n",
       "    category_name_preprocessed Tier_2 Tier_3  \\\n",
       "id                                             \n",
       "46            women/shoe/boots   shoe  boots   \n",
       "88            women/shoe/boots   shoe  boots   \n",
       "212           women/shoe/boots   shoe  boots   \n",
       "289           women/shoe/boots   shoe  boots   \n",
       "299           women/shoe/boots   shoe  boots   \n",
       "\n",
       "                            item_description_processed  \n",
       "id                                                      \n",
       "46        corral boots excellent condition barely used  \n",
       "88   super cute brown cognac knee high riding boots...  \n",
       "212                                            new box  \n",
       "289                      made withstand winter climate  \n",
       "299  unique super cute warm euc selling lining insi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the processed test dataset\n",
    "\n",
    "df_test = pd.read_csv(\"test_processed.csv\",index_col=[\"id\"])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the \"df\" dataframe into train and validation dataframe\n",
    "\n",
    "df_train,df_val = train_test_split(df,test_size=0.1,random_state = 3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape =  (61560, 14)\n",
      "Validation Shape =  (6840, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Shape = \",df_train.shape)\n",
    "print(\"Validation Shape = \",df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_item_cond = df_train.item_condition_id\n",
    "val_item_cond = df_val.item_condition_id\n",
    "test_item_cond = df_test.item_condition_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_shipping = df_train.shipping\n",
    "val_shipping = df_val.shipping\n",
    "test_shipping = df_test.shipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing and Padding\n",
    "\n",
    "def text_vectorizer(feature):\n",
    "\n",
    "    tk = Tokenizer()\n",
    "    tk.fit_on_texts(df_train[feature].apply(str))\n",
    "    \n",
    "    tk_train = tk.texts_to_sequences(df_train[feature].apply(str))\n",
    "    tk_val = tk.texts_to_sequences(df_val[feature].apply(str))\n",
    "    \n",
    "    max_length = df_train[feature].apply(lambda x :len(str(x).split())).max()\n",
    "    vocab_size = len(tk.word_index) + 1\n",
    "    \n",
    "    train_pad= pad_sequences(tk_train,padding=\"post\",maxlen = max_length)\n",
    "    val_pad = pad_sequences(tk_val,padding = \"post\", maxlen = max_length)\n",
    "    \n",
    "    # Returning the tokenizer, max length , padded train sequences , padded validation sequences \n",
    "    return tk , max_length, vocab_size, train_pad , val_pad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing Brand_name-processed and padding\n",
    "\n",
    "tk_brand_name,max_length_brand_name,vocab_size_brand_name,train_brand_name_pad , val_brand_name_pad = text_vectorizer(\"brand_name_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_brand_name_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape =  (61560, 5)\n",
      "Validation Shape =  (6840, 5)\n",
      "Max Length =  5\n",
      "Vocal Size=  1390\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Shape = \",train_brand_name_pad.shape)\n",
    "print(\"Validation Shape = \",val_brand_name_pad.shape)\n",
    "print(\"Max Length = \", max_length_brand_name)\n",
    "print(\"Vocal Size= \",vocab_size_brand_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31789, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing Brand_name_processed and padding for test data\n",
    "\n",
    "test_brand_name_pad = pad_sequences(tk_brand_name.texts_to_sequences(df_test.brand_name_processed),maxlen=max_length_brand_name,padding=\"post\")\n",
    "test_brand_name_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing and padding tier2 for train and validation dataset\n",
    "\n",
    "tk_tier2 , max_length_tier2 ,vocab_size_tier2, train_tier2_pad , val_tier2_pad = text_vectorizer(\"Tier_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape = (61560, 2)\n",
      "Validation Shape = (6840, 2)\n",
      "Max Length =  2\n",
      "Vocal Size=  15\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Shape =\",train_tier2_pad.shape)\n",
    "print(\"Validation Shape =\",val_tier2_pad.shape)\n",
    "print(\"Max Length = \", max_length_tier2)\n",
    "print(\"Vocal Size= \",vocab_size_tier2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31789, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing and padding tier2 for test dataset\n",
    "\n",
    "test_tier2_pad = pad_sequences(tk_tier2.texts_to_sequences(df_test.Tier_2),maxlen=max_length_tier2,padding=\"post\")\n",
    "test_tier2_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing and padding tier3 for train and validation dataset\n",
    "\n",
    "tk_tier3 , max_length_tier3 , vocab_size_tier3, train_tier3_pad , val_tier3_pad = text_vectorizer(\"Tier_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape =  (61560, 3)\n",
      "Validation Shape =  (6840, 3)\n",
      "Max Length = 3\n",
      "Vocal Size = 33\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Shape = \",train_tier3_pad.shape)\n",
    "print(\"Validation Shape = \",val_tier3_pad.shape)\n",
    "print(\"Max Length =\", max_length_tier3)\n",
    "print(\"Vocal Size =\",vocab_size_tier3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31789, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing and padding tier3 for test dataset\n",
    "\n",
    "test_tier3_pad = pad_sequences(tk_tier3.texts_to_sequences(df_test.Tier_3),maxlen=max_length_tier3,padding=\"post\")\n",
    "test_tier3_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing and padding name_processed for train and validation dataset\n",
    "\n",
    "tk_name_processed , max_length_name_processed ,vocab_size_name_processed , train_name_processed_pad , val_name_processed_pad = text_vectorizer(\"name_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape =  (61560, 10)\n",
      "Validation Shape =  (6840, 10)\n",
      "Max Length =  10\n",
      "Vocal Size=  12137\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Shape = \",train_name_processed_pad.shape)\n",
    "print(\"Validation Shape = \",val_name_processed_pad.shape)\n",
    "print(\"Max Length = \", max_length_name_processed)\n",
    "print(\"Vocal Size= \",vocab_size_name_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31789, 10)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing and padding name_processed for test dataset\n",
    "\n",
    "test_name_processed_pad = pad_sequences(tk_name_processed.texts_to_sequences(df_test.name_processed),maxlen=max_length_name_processed,padding=\"post\")\n",
    "test_name_processed_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing and padding item_description for train and validation dataset\n",
    "\n",
    "tk_desc , max_len_desc ,vocab_size_desc,train_desc_pad , val_desc_pad = text_vectorizer(\"item_description_processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trian Shape =  (61560, 115)\n",
      "Validation Shape =  (6840, 115)\n",
      "Max Length =  115\n",
      "Vocal Size=  18484\n"
     ]
    }
   ],
   "source": [
    "print(\"Trian Shape = \",train_desc_pad.shape)\n",
    "print(\"Validation Shape = \",val_desc_pad.shape)\n",
    "print(\"Max Length = \", max_len_desc)\n",
    "print(\"Vocal Size= \",vocab_size_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31789, 115)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing and padding item_description for test dataset\n",
    "\n",
    "test_item_desc_pad = pad_sequences(tk_desc.texts_to_sequences(df_test.item_description_processed),maxlen=max_len_desc,padding=\"post\")\n",
    "test_item_desc_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target values (log_price)\n",
    "\n",
    "y_train = df_train.log_price\n",
    "y_val = df_val.log_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the features as a list\n",
    "\n",
    "x_train = [train_item_cond,train_shipping,train_brand_name_pad,train_tier2_pad,train_tier3_pad,train_name_processed_pad,train_desc_pad]\n",
    "\n",
    "x_val= [val_item_cond,val_shipping,val_brand_name_pad,val_tier2_pad,val_tier3_pad,val_name_processed_pad,val_desc_pad]\n",
    "\n",
    "x_test= [test_item_cond,test_shipping,test_brand_name_pad,test_tier2_pad,test_tier3_pad,test_name_processed_pad,test_item_desc_pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Jayendran Kannaiyan\\.thumbnails\\anacond\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Jayendran Kannaiyan\\.thumbnails\\anacond\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Item_condition_id\n",
    "inp1 = layers.Input(shape=(1)) \n",
    "emb1  = layers.Embedding(6,10,input_length=1)(inp1) \n",
    "flat1 = layers.Flatten()(emb1) \n",
    "\n",
    "\n",
    "# Shipping\n",
    "inp2 = layers.Input(shape=(1))  \n",
    "d2 = layers.Dense(10,activation=\"relu\")(inp2) \n",
    "\n",
    "\n",
    "# Brand_name_processed\n",
    "inp3 = layers.Input(shape= (5)) \n",
    "emb3 = layers.Embedding(vocab_size_brand_name ,16 ,input_length= 8 )(inp3) \n",
    "flat3 = layers.Flatten()(emb3) \n",
    "\n",
    "\n",
    "# Tier_2\n",
    "inp5= layers.Input(shape = (2)) \n",
    "emb5 = layers.Embedding(vocab_size_tier2 , 16 ,input_length= 4 )(inp5) \n",
    "flat5 = layers.Flatten()(emb5)\n",
    "\n",
    "# Tier_3\n",
    "inp6= layers.Input(shape = (3))  \n",
    "emb6 = layers.Embedding(vocab_size_tier3, 16 ,input_length= 6 )(inp6) \n",
    "flat6 = layers.Flatten()(emb6) \n",
    "\n",
    "# Name_processed\n",
    "inp7= layers.Input(shape = (10)) \n",
    "emb7 = layers.Embedding(vocab_size_name_processed,20 ,input_length= 13 )(inp7) \n",
    "lstm7 = layers.GRU(64,return_sequences=True)(emb7) \n",
    "flat7 = layers.Flatten()(lstm7) \n",
    "\n",
    "# Item_description_processed\n",
    "inp8= layers.Input(shape = (115)) \n",
    "emb8 = layers.Embedding(vocab_size_desc , 40 , input_length= 193 )(inp8) \n",
    "lstm8 = layers.GRU(64,return_sequences=True)(emb8) \n",
    "flat8 = layers.Flatten()(lstm8)\n",
    "\n",
    "# Concatenate\n",
    "concat = layers.Concatenate()([flat1,d2,flat3,flat5,flat6,flat7,flat8])\n",
    "\n",
    "# Dense layer\n",
    "dense1 = layers.Dense(512,activation=\"relu\")(concat)\n",
    "# Dropout layer\n",
    "drop2 = layers.Dropout(0.2)(dense1)\n",
    "# Dense layer\n",
    "dense2 = layers.Dense(256,activation=\"relu\")(drop2)\n",
    "# Dropout layer\n",
    "drop2 = layers.Dropout(0.3)(dense2)\n",
    "# Dense layer\n",
    "dense3 = layers.Dense(128,activation=\"relu\")(drop2)\n",
    "# Dropout layer\n",
    "drop2 = layers.Dropout(0.4)(dense3)\n",
    "# Batchnorm layer\n",
    "bn2  = layers.BatchNormalization()(drop2)\n",
    "# Dense layer\n",
    "dense4 = layers.Dense(1,activation=\"linear\")(bn2)\n",
    "\n",
    "# Model\n",
    "model =  Model(inputs= [inp1,inp2,inp3,inp5,inp6,inp7,inp8],outputs=dense4)\n",
    "\n",
    "# Schedule\n",
    "def schedule(epoch,lr):\n",
    "    if epoch<=2:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr*0.1\n",
    "\n",
    "# Callbacks\n",
    "lr = tf.keras.callbacks.LearningRateScheduler(schedule,verbose=1)\n",
    "save = tf.keras.callbacks.ModelCheckpoint(\"best.h5\",monitor=\"val_root_mean_squared_error\",mode=\"min\",save_best_only=True, save_weights_only=True,verbose=1)\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor=\"val_root_mean_squared_error\",min_delta= 0.01, patience=2,mode=\"min\" )\n",
    "\n",
    "# Compiling model\n",
    "model.compile(optimizer=\"adam\",loss=\"mse\",metrics= [tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 61560 samples, validate on 6840 samples\n",
      "WARNING:tensorflow:From C:\\Users\\Jayendran Kannaiyan\\.thumbnails\\anacond\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 1/10\n",
      "61500/61560 [============================>.] - ETA: 0s - loss: 1.0072 - root_mean_squared_error: 1.0036\n",
      "Epoch 00001: val_root_mean_squared_error improved from inf to 0.58201, saving model to best.h5\n",
      "61560/61560 [==============================] - 99s 2ms/sample - loss: 1.0066 - root_mean_squared_error: 1.0033 - val_loss: 0.3387 - val_root_mean_squared_error: 0.5820\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 2/10\n",
      "61500/61560 [============================>.] - ETA: 0s - loss: 0.2509 - root_mean_squared_error: 0.5009\n",
      "Epoch 00002: val_root_mean_squared_error improved from 0.58201 to 0.49718, saving model to best.h5\n",
      "61560/61560 [==============================] - 92s 1ms/sample - loss: 0.2509 - root_mean_squared_error: 0.5009 - val_loss: 0.2472 - val_root_mean_squared_error: 0.4972\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0010000000474974513.\n",
      "Epoch 3/10\n",
      "61500/61560 [============================>.] - ETA: 0s - loss: 0.2123 - root_mean_squared_error: 0.4607\n",
      "Epoch 00003: val_root_mean_squared_error did not improve from 0.49718\n",
      "61560/61560 [==============================] - 96s 2ms/sample - loss: 0.2123 - root_mean_squared_error: 0.4607 - val_loss: 0.2579 - val_root_mean_squared_error: 0.5078\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 4/10\n",
      "61500/61560 [============================>.] - ETA: 0s - loss: 0.1699 - root_mean_squared_error: 0.4122\n",
      "Epoch 00004: val_root_mean_squared_error improved from 0.49718 to 0.49618, saving model to best.h5\n",
      "61560/61560 [==============================] - 89s 1ms/sample - loss: 0.1699 - root_mean_squared_error: 0.4122 - val_loss: 0.2462 - val_root_mean_squared_error: 0.4962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x226be257b00>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "\n",
    "model.fit(x=x_train,y=y_train,validation_data=(x_val,y_val) ,epochs=10,batch_size = 100,callbacks=[save,lr,earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model\n",
    "model.load_weights(\"best.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6840/6840 [==============================] - 1s 194us/sample - loss: 0.2462 - root_mean_squared_error: 0.4962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24619017733119383, 0.49617553]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "model.evaluate(x_val,y_val,batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the log price to actual price\n",
    "\n",
    "def log_to_actual(log):\n",
    "    return np.exp(log)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31789/31789 [==============================] - 11s 349us/sample\n"
     ]
    }
   ],
   "source": [
    "# Predicting the results for test dataset\n",
    "\n",
    "x_test_pred = model.predict(x_test,batch_size=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>44.822487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>32.020103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>54.267452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>35.186333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>42.049774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         price\n",
       "id            \n",
       "46   44.822487\n",
       "88   32.020103\n",
       "212  54.267452\n",
       "289  35.186333\n",
       "299  42.049774"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict = pd.DataFrame(log_to_actual(x_test_pred),columns=[\"price\"])\n",
    "test_predict.index = df_test.index\n",
    "test_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the predicted values\n",
    "\n",
    "test_predict.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training error : 0.4122\n",
    "# Validation error : 0.4962"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
